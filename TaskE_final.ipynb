{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 195,
   "id": "9ca7fe1a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#importing libraries\n",
    "import pandas as pd\n",
    "from textblob import TextBlob\n",
    "import nltk\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk import pos_tag\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.corpus import wordnet\n",
    "import collections\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "import itertools\n",
    "from collections import Counter"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a39ef3ea",
   "metadata": {},
   "source": [
    "### Loading comments and model-brands data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "id": "7e396d9f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>page</th>\n",
       "      <th>comment_id</th>\n",
       "      <th>user_id</th>\n",
       "      <th>date</th>\n",
       "      <th>comment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>3504465</td>\n",
       "      <td>410384</td>\n",
       "      <td>April 11, 2007 6:52PM</td>\n",
       "      <td>Hi Pat:You forgot the Chrysler Sebring</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>3515400</td>\n",
       "      <td>209396</td>\n",
       "      <td>April 11, 2007 7:33PM</td>\n",
       "      <td>I'm sure some folks would appreciate having th...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>3516719</td>\n",
       "      <td>457562</td>\n",
       "      <td>April 12, 2007 6:51AM</td>\n",
       "      <td>You can try to revive this topic but without b...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>3517791</td>\n",
       "      <td>410027</td>\n",
       "      <td>April 12, 2007 8:43AM</td>\n",
       "      <td>Model vs. model is exactly what we're here for...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>3518875</td>\n",
       "      <td>411850</td>\n",
       "      <td>April 13, 2007 11:49AM</td>\n",
       "      <td>The Altima is my favorite of the bunch. It is ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   page  comment_id  user_id                    date  \\\n",
       "0     1     3504465   410384   April 11, 2007 6:52PM   \n",
       "1     1     3515400   209396   April 11, 2007 7:33PM   \n",
       "2     1     3516719   457562   April 12, 2007 6:51AM   \n",
       "3     1     3517791   410027   April 12, 2007 8:43AM   \n",
       "4     1     3518875   411850  April 13, 2007 11:49AM   \n",
       "\n",
       "                                             comment  \n",
       "0           Hi Pat:You forgot the Chrysler Sebring    \n",
       "1  I'm sure some folks would appreciate having th...  \n",
       "2  You can try to revive this topic but without b...  \n",
       "3  Model vs. model is exactly what we're here for...  \n",
       "4  The Altima is my favorite of the bunch. It is ...  "
      ]
     },
     "execution_count": 103,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = pd.read_csv('comments_raw.csv')[:5000]\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "id": "892f0523",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>acura</th>\n",
       "      <th>integra</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>acura</td>\n",
       "      <td>Legend</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>acura</td>\n",
       "      <td>vigor</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>acura</td>\n",
       "      <td>rlx</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>acura</td>\n",
       "      <td>ILX</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>acura</td>\n",
       "      <td>MDX</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   acura integra\n",
       "0  acura  Legend\n",
       "1  acura   vigor\n",
       "2  acura     rlx\n",
       "3  acura     ILX\n",
       "4  acura     MDX"
      ]
     },
     "execution_count": 104,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = pd.read_csv('models.csv')\n",
    "model.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "id": "7ec7b838",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_dict = dict(zip(model.integra, model.acura))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "id": "cfbb714f",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_dict['integra']='acura'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "id": "6b4c48af",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'car'"
      ]
     },
     "execution_count": 107,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_dict['cars']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "16914b2f",
   "metadata": {},
   "source": [
    "#### Removing non-brand keys from the model-brand dictionary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "id": "53baac1a",
   "metadata": {},
   "outputs": [],
   "source": [
    "del model_dict[\"cars\"]\n",
    "del model_dict[\"seats\"]\n",
    "del model_dict[\"problems\"]\n",
    "del model_dict[\"sedans\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "475594ee",
   "metadata": {},
   "source": [
    "#### Replacing models with brands"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "id": "762b7e18",
   "metadata": {},
   "outputs": [],
   "source": [
    "def replace_all(text):\n",
    "    for i, j in model_dict.items():\n",
    "        text = text.replace(j.lower(), i.lower())\n",
    "    return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "id": "82ce45d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "data['com_replaced'] = data['comment'].apply(replace_all)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "id": "68bf5b81",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['audi',\n",
       " 'toyata',\n",
       " 'kia',\n",
       " 'ford',\n",
       " 'dodge',\n",
       " 'volvo',\n",
       " 'pontiac',\n",
       " 'acura',\n",
       " 'subaru',\n",
       " 'cadillac',\n",
       " 'hyndai kia',\n",
       " 'buick',\n",
       " 'lincoln',\n",
       " 'chrysler',\n",
       " 'mitsubishi',\n",
       " 'honda',\n",
       " 'mazda',\n",
       " 'volkswagen',\n",
       " 'hyundai',\n",
       " 'infiniti',\n",
       " 'mercedes',\n",
       " 'chevrolet',\n",
       " 'saturn',\n",
       " 'mercury',\n",
       " 'bmw',\n",
       " 'suzuki',\n",
       " 'toyota',\n",
       " 'nissan']"
      ]
     },
     "execution_count": 111,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "models_input = list(set(list(model_dict.values())))\n",
    "models_input"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "id": "1d355a8d",
   "metadata": {},
   "outputs": [],
   "source": [
    "brand_list = models_input\n",
    "#brand_list.remove(\"problem\")\n",
    "#brand_list.remove(\"car\")\n",
    "#brand_list.remove(\"seat\")\n",
    "#brand_list.remove(\"sedan\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "id": "cc97c863",
   "metadata": {},
   "outputs": [],
   "source": [
    "wl = WordNetLemmatizer()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2fac0639",
   "metadata": {},
   "source": [
    "### Data cleaning and pre-processing"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3d59322b",
   "metadata": {},
   "source": [
    "#### Getting part-of-speech tags for comments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "id": "4768943e",
   "metadata": {},
   "outputs": [],
   "source": [
    "pos_dict = {'J':wordnet.ADJ, 'V':wordnet.VERB, 'N':wordnet.NOUN, 'R':wordnet.ADV}\n",
    "def token_stop_pos(text):\n",
    "    tags = pos_tag(word_tokenize(text))\n",
    "    newlist = []\n",
    "    for word, tag in tags:\n",
    "        if word.lower() not in set(stopwords.words('english')):\n",
    "            newlist.append(tuple([word.lower(), pos_dict.get(tag[0])]))\n",
    "    return newlist\n",
    "\n",
    "data['pos'] = data['comment'].apply(token_stop_pos)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b1caa50c",
   "metadata": {},
   "source": [
    "#### lemmatizing comments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "id": "399bc92f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def lemmatize(pos_data):\n",
    "    lemma_rew = \" \"\n",
    "    for word, pos in pos_data:\n",
    "        if not pos:\n",
    "            lemma = word\n",
    "            lemma_rew = lemma_rew + \" \" + lemma\n",
    "        else:\n",
    "            lemma = wl.lemmatize(word, pos=pos)\n",
    "            lemma_rew = lemma_rew + \" \" + lemma\n",
    "    return lemma_rew\n",
    "\n",
    "data['Lemma'] = data['pos'].apply(lemmatize)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "id": "2776d7b5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>page</th>\n",
       "      <th>comment_id</th>\n",
       "      <th>user_id</th>\n",
       "      <th>date</th>\n",
       "      <th>comment</th>\n",
       "      <th>com_replaced</th>\n",
       "      <th>pos</th>\n",
       "      <th>Lemma</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>3504465</td>\n",
       "      <td>410384</td>\n",
       "      <td>April 11, 2007 6:52PM</td>\n",
       "      <td>Hi Pat:You forgot the Chrysler Sebring</td>\n",
       "      <td>Hi Pat:You forgot the Chrysler Sebring</td>\n",
       "      <td>[(hi, n), (pat, n), (:, None), (forgot, v), (c...</td>\n",
       "      <td>hi pat : forget chrysler sebring</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>3515400</td>\n",
       "      <td>209396</td>\n",
       "      <td>April 11, 2007 7:33PM</td>\n",
       "      <td>I'm sure some folks would appreciate having th...</td>\n",
       "      <td>I'm sure some folks would appreciate having th...</td>\n",
       "      <td>[('m, v), (sure, a), (folks, n), (would, None)...</td>\n",
       "      <td>'m sure folk would appreciate malibu include...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>3516719</td>\n",
       "      <td>457562</td>\n",
       "      <td>April 12, 2007 6:51AM</td>\n",
       "      <td>You can try to revive this topic but without b...</td>\n",
       "      <td>You can try to revive this topic but without b...</td>\n",
       "      <td>[(try, v), (revive, v), (topic, n), (without, ...</td>\n",
       "      <td>try revive topic without able discuss ( howe...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>3517791</td>\n",
       "      <td>410027</td>\n",
       "      <td>April 12, 2007 8:43AM</td>\n",
       "      <td>Model vs. model is exactly what we're here for...</td>\n",
       "      <td>Model vs. model is exactly what we're here for...</td>\n",
       "      <td>[(model, n), (vs., None), (model, n), (exactly...</td>\n",
       "      <td>model vs. model exactly 're ! manufacturer v...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>3518875</td>\n",
       "      <td>411850</td>\n",
       "      <td>April 13, 2007 11:49AM</td>\n",
       "      <td>The Altima is my favorite of the bunch. It is ...</td>\n",
       "      <td>The Altima is my favorite of the bunch. It is ...</td>\n",
       "      <td>[(altima, n), (favorite, n), (bunch, n), (., N...</td>\n",
       "      <td>altima favorite bunch . amongst fast best ha...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   page  comment_id  user_id                    date  \\\n",
       "0     1     3504465   410384   April 11, 2007 6:52PM   \n",
       "1     1     3515400   209396   April 11, 2007 7:33PM   \n",
       "2     1     3516719   457562   April 12, 2007 6:51AM   \n",
       "3     1     3517791   410027   April 12, 2007 8:43AM   \n",
       "4     1     3518875   411850  April 13, 2007 11:49AM   \n",
       "\n",
       "                                             comment  \\\n",
       "0           Hi Pat:You forgot the Chrysler Sebring     \n",
       "1  I'm sure some folks would appreciate having th...   \n",
       "2  You can try to revive this topic but without b...   \n",
       "3  Model vs. model is exactly what we're here for...   \n",
       "4  The Altima is my favorite of the bunch. It is ...   \n",
       "\n",
       "                                        com_replaced  \\\n",
       "0           Hi Pat:You forgot the Chrysler Sebring     \n",
       "1  I'm sure some folks would appreciate having th...   \n",
       "2  You can try to revive this topic but without b...   \n",
       "3  Model vs. model is exactly what we're here for...   \n",
       "4  The Altima is my favorite of the bunch. It is ...   \n",
       "\n",
       "                                                 pos  \\\n",
       "0  [(hi, n), (pat, n), (:, None), (forgot, v), (c...   \n",
       "1  [('m, v), (sure, a), (folks, n), (would, None)...   \n",
       "2  [(try, v), (revive, v), (topic, n), (without, ...   \n",
       "3  [(model, n), (vs., None), (model, n), (exactly...   \n",
       "4  [(altima, n), (favorite, n), (bunch, n), (., N...   \n",
       "\n",
       "                                               Lemma  \n",
       "0                   hi pat : forget chrysler sebring  \n",
       "1    'm sure folk would appreciate malibu include...  \n",
       "2    try revive topic without able discuss ( howe...  \n",
       "3    model vs. model exactly 're ! manufacturer v...  \n",
       "4    altima favorite bunch . amongst fast best ha...  "
      ]
     },
     "execution_count": 116,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5f851a36",
   "metadata": {},
   "source": [
    "#### performing sentiment analysis on comments"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5c985f25",
   "metadata": {},
   "source": [
    "This is to understand the context of the aspirational words used with reference to brands.\n",
    "TextBlob functions gives output in the form a tuple with two values:\n",
    "- Positivity (range: -1 to 1): Here, 1 and -1 represent extreme positive and negative ends respectively.\n",
    "- Subjectivity (range: 0 to 1): Here, 0 represents the statement in general context and one represents the statement in subjective context."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "id": "7d5b2d8e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def datablob(lemma):\n",
    "    return TextBlob(lemma).sentiment\n",
    "\n",
    "data['Blob'] = data['Lemma'].apply(datablob)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6668fb5f",
   "metadata": {},
   "source": [
    "#### Defining a set of aspirational words to look out for in comments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "id": "d15496fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "aspiration = ['premium', 'luxury', 'lux', 'grace', 'style', 'buy', 'wishlist', 'wish', 'own', 'dream', 'expensive', \n",
    "              'class', 'smooth', 'pricey', 'elite', 'favorite','appreciate', 'brand', 'have']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4842130b",
   "metadata": {},
   "source": [
    "#### Finding aspirational words from above defined list in the comments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "id": "645c1a6f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def aspire(Lemma):\n",
    "    tokens = word_tokenize(Lemma)\n",
    "    aspire_words=[]\n",
    "    for item in tokens: \n",
    "        if item.lower() in (string.lower() for string in aspiration) and item.lower() not in (string.lower() for string in aspire_words):\n",
    "            aspire_words.append(item.lower())\n",
    "    return aspire_words\n",
    "\n",
    "data['Aspire'] = data['Lemma'].apply(aspire)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0131f9c0",
   "metadata": {},
   "source": [
    "#### Only keeping rows which detected aspirational words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "id": "32c2c7b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = data.loc[data['Aspire'].str.len() >= 1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "id": "60aca4a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "pos_col = df['pos'].to_list()\n",
    "#pos_col\n",
    "lst_comment_words = []\n",
    "for sentence in pos_col:\n",
    "    new_sentence = []\n",
    "    for t in sentence:\n",
    "        new_sentence.append(t[0])\n",
    "    lst_comment_words.append(new_sentence)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "id": "9d29f849",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/qd/mwbvwnnn27n7mvvwgw8sy4_40000gn/T/ipykernel_3210/4229110624.py:1: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df['lst_of_words'] = lst_comment_words\n"
     ]
    }
   ],
   "source": [
    "df['lst_of_words'] = lst_comment_words"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a50691a8",
   "metadata": {},
   "source": [
    "#### Getting brand names from the comments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "id": "36ae7b4d",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_lookup = pd.read_csv('models.csv',header=None)\n",
    "brands_np = model_lookup.iloc[:,0].unique()\n",
    "model_np = model_lookup.iloc[:,1].unique()\n",
    "\n",
    "def get_brand(sentence):\n",
    "    result = []\n",
    "    # lower case all strings\n",
    "    sentence_lower = [x.lower() for x in sentence]\n",
    "    # drop duplicates\n",
    "    sentence_lower = list(dict.fromkeys(sentence_lower))\n",
    "    # go through the list of car brands\n",
    "    for brand in brands_np:\n",
    "        if brand.lower() in sentence_lower:\n",
    "            if brand.lower() not in result:\n",
    "                result.append(brand.lower())\n",
    "    # go through the model list, retraive brand info\n",
    "    for i,model in enumerate(model_lookup.iloc[:,1]):\n",
    "        candidate_brands = []\n",
    "        for j,word in enumerate(sentence_lower):\n",
    "            if model.lower() == word:\n",
    "                candidate_brands.append(model_lookup.iloc[i,0])\n",
    "        if len(candidate_brands) == 1 and candidate_brands[0].lower() not in result:\n",
    "            result.append(candidate_brands[0].lower())\n",
    "        elif len(candidate_brands) > 1:\n",
    "            flg = 0\n",
    "            for brand_c in candidate_brands:\n",
    "                if brand_c in result:\n",
    "                    flg += 1\n",
    "            if flg == 0:\n",
    "                result.append(candidate_brands[0].lower())\n",
    "                    \n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "id": "6f1fba48",
   "metadata": {},
   "outputs": [],
   "source": [
    "brands_in_comments = list(map(lambda x: get_brand(x), lst_comment_words))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "id": "0ab860c6",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/qd/mwbvwnnn27n7mvvwgw8sy4_40000gn/T/ipykernel_3210/2752327559.py:1: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df['names'] = brands_in_comments\n"
     ]
    }
   ],
   "source": [
    "df['names'] = brands_in_comments"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "442a3e23",
   "metadata": {},
   "source": [
    "#### Dropping other columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "id": "6ec52856",
   "metadata": {},
   "outputs": [],
   "source": [
    "df1 = df.drop(['page', 'comment_id', 'comment', 'user_id', 'date'], axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "21801b07",
   "metadata": {},
   "source": [
    "#### Filtering data based on positivity and subjectivity\n",
    "- Positivity: Keeping data with positive values above 0 so that the brands are mentioned in positive context wrt aspirational words.\n",
    "- Subjectivity: Keeping data with subjective score>=0.5 so that we can assume its the subjective opinion of user regarding the brand which would suggest the user's preference towards the brand."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "id": "31639da3",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/annary1996/opt/anaconda3/lib/python3.8/site-packages/pandas/core/frame.py:4906: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  return super().drop(\n"
     ]
    }
   ],
   "source": [
    "df2 = df1.loc[(df1['Blob'].str[0] >= 0) & (df1['Blob'].str[1] >= 0.5)]\n",
    "df2.drop(['pos', 'Blob'], axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "id": "4b3c23f6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>com_replaced</th>\n",
       "      <th>Lemma</th>\n",
       "      <th>Aspire</th>\n",
       "      <th>lst_of_words</th>\n",
       "      <th>names</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>I'm sure some folks would appreciate having th...</td>\n",
       "      <td>'m sure folk would appreciate malibu include...</td>\n",
       "      <td>[appreciate]</td>\n",
       "      <td>['m, sure, folks, would, appreciate, malibu, i...</td>\n",
       "      <td>[chevrolet]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>The Altima is my favorite of the bunch. It is ...</td>\n",
       "      <td>altima favorite bunch . amongst fast best ha...</td>\n",
       "      <td>[favorite, expensive]</td>\n",
       "      <td>[altima, favorite, bunch, ., amongst, fastest,...</td>\n",
       "      <td>[car, ford, hyundai, kia, mazda, nissan, honda...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>My daily driver is an '03 Maxima, and the '07 ...</td>\n",
       "      <td>daily driver '03 maximum , '07 altima feel f...</td>\n",
       "      <td>[pricey]</td>\n",
       "      <td>[daily, driver, '03, maxima, ,, '07, altima, f...</td>\n",
       "      <td>[car, ford, mazda, nissan]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>Its interesting how that happens. There is no ...</td>\n",
       "      <td>interesting happen . real successor contour ...</td>\n",
       "      <td>[pricey]</td>\n",
       "      <td>[interesting, happens, ., real, successor, con...</td>\n",
       "      <td>[car, ford, mazda, nissan]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>I have been driving Accords for 16 years now. ...</td>\n",
       "      <td>drive accord 16 year . 12 year first one , 4...</td>\n",
       "      <td>[smooth, buy, brand]</td>\n",
       "      <td>[driving, accords, 16, years, ., 12, years, fi...</td>\n",
       "      <td>[car, sedan, honda]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                         com_replaced  \\\n",
       "1   I'm sure some folks would appreciate having th...   \n",
       "4   The Altima is my favorite of the bunch. It is ...   \n",
       "9   My daily driver is an '03 Maxima, and the '07 ...   \n",
       "11  Its interesting how that happens. There is no ...   \n",
       "24  I have been driving Accords for 16 years now. ...   \n",
       "\n",
       "                                                Lemma                 Aspire  \\\n",
       "1     'm sure folk would appreciate malibu include...           [appreciate]   \n",
       "4     altima favorite bunch . amongst fast best ha...  [favorite, expensive]   \n",
       "9     daily driver '03 maximum , '07 altima feel f...               [pricey]   \n",
       "11    interesting happen . real successor contour ...               [pricey]   \n",
       "24    drive accord 16 year . 12 year first one , 4...   [smooth, buy, brand]   \n",
       "\n",
       "                                         lst_of_words  \\\n",
       "1   ['m, sure, folks, would, appreciate, malibu, i...   \n",
       "4   [altima, favorite, bunch, ., amongst, fastest,...   \n",
       "9   [daily, driver, '03, maxima, ,, '07, altima, f...   \n",
       "11  [interesting, happens, ., real, successor, con...   \n",
       "24  [driving, accords, 16, years, ., 12, years, fi...   \n",
       "\n",
       "                                                names  \n",
       "1                                         [chevrolet]  \n",
       "4   [car, ford, hyundai, kia, mazda, nissan, honda...  \n",
       "9                          [car, ford, mazda, nissan]  \n",
       "11                         [car, ford, mazda, nissan]  \n",
       "24                                [car, sedan, honda]  "
      ]
     },
     "execution_count": 129,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df2.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b4769fc4",
   "metadata": {},
   "source": [
    "### Calculations and frequencies"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ad7ca4f1",
   "metadata": {},
   "source": [
    "#### Calculating frequency of different aspirational words from the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "id": "2a5af664",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_asp = data['Aspire'].to_list()\n",
    "asp_count = [0]*len(aspiration)\n",
    "for i,w in enumerate(aspiration):\n",
    "    for sentence in data_asp:\n",
    "        if w.lower() in sentence:\n",
    "            asp_count[i] += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "id": "bd3d47de",
   "metadata": {},
   "outputs": [],
   "source": [
    "asp_count_pd = pd.DataFrame({'aspiration':aspiration,'count':asp_count})"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "58aa74a0",
   "metadata": {},
   "source": [
    "#### Calculating frequency of combination of brands and aspirational words from the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "id": "e831b000",
   "metadata": {},
   "outputs": [],
   "source": [
    "combinations = []\n",
    "for w1 in brand_list:\n",
    "    for w2 in aspiration:\n",
    "        temp = (w1,w2)\n",
    "        combinations.append(temp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 181,
   "id": "fa45ca46",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1572, 7)"
      ]
     },
     "execution_count": 181,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df1.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 178,
   "id": "55debf42",
   "metadata": {},
   "outputs": [],
   "source": [
    "combination_freq = [0]*len(combinations)\n",
    "\n",
    "lst_asp = df1.Aspire.to_list()\n",
    "lst_brands = df1.names.to_list()\n",
    "for i,c in enumerate(combinations):\n",
    "    for j, asp in enumerate(lst_asp):\n",
    "        if c[0].lower() in lst_brands[j] and c[1].lower() in asp:\n",
    "            combination_freq[i] += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 185,
   "id": "02f42844",
   "metadata": {},
   "outputs": [],
   "source": [
    "combo_count = pd.DataFrame({'combo':combinations,'count':combination_freq})#.to_csv('combo_count.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 186,
   "id": "44965886",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>combo</th>\n",
       "      <th>count</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>(audi, premium)</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>(audi, luxury)</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>(audi, lux)</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>(audi, grace)</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>(audi, style)</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>527</th>\n",
       "      <td>(nissan, elite)</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>528</th>\n",
       "      <td>(nissan, favorite)</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>529</th>\n",
       "      <td>(nissan, appreciate)</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>530</th>\n",
       "      <td>(nissan, brand)</td>\n",
       "      <td>21</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>531</th>\n",
       "      <td>(nissan, have)</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>532 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                    combo  count\n",
       "0         (audi, premium)      2\n",
       "1          (audi, luxury)      2\n",
       "2             (audi, lux)      0\n",
       "3           (audi, grace)      0\n",
       "4           (audi, style)      2\n",
       "..                    ...    ...\n",
       "527       (nissan, elite)      0\n",
       "528    (nissan, favorite)      7\n",
       "529  (nissan, appreciate)      4\n",
       "530       (nissan, brand)     21\n",
       "531        (nissan, have)      1\n",
       "\n",
       "[532 rows x 2 columns]"
      ]
     },
     "execution_count": 186,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "combo_count"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0a0f7461",
   "metadata": {},
   "source": [
    "#### Preparing data for lift calculation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9d3978fb",
   "metadata": {},
   "source": [
    "#### Converting brand count to dictionary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "bfe027d4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "         brand  count\n",
      "0          car   2331\n",
      "1        honda   2061\n",
      "2         ford   1339\n",
      "3       toyota    937\n",
      "4      hyundai    576\n",
      "5        mazda    552\n",
      "6       nissan    514\n",
      "7        sedan    408\n",
      "8      problem    343\n",
      "9    chevrolet    235\n",
      "10      saturn    231\n",
      "11    chrysler    211\n",
      "12        seat    194\n",
      "13      subaru    153\n",
      "14         kia    132\n",
      "15         bmw    108\n",
      "16  volkswagen    100\n",
      "17     mercury     81\n",
      "18       dodge     72\n",
      "19       acura     61\n",
      "20       buick     57\n",
      "21     pontiac     56\n",
      "22  mitsubishi     46\n",
      "23     lincoln     45\n",
      "24        audi     41\n",
      "25       volvo     30\n",
      "26    mercedes     26\n",
      "27    cadillac     25\n",
      "28    infiniti     10\n",
      "29      suzuki      8\n"
     ]
    }
   ],
   "source": [
    "ctr_brands = pd.read_csv('brand_count.csv')\n",
    "print(ctr_brands)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "id": "e6bb2e36",
   "metadata": {},
   "outputs": [],
   "source": [
    "ctr_brands_car = ctr_brands.loc[~ctr_brands.brand.isin(['car','problem','sedan','seat'])]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "id": "991206f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "N = len(data)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ca6e3654",
   "metadata": {},
   "source": [
    "#### Calculating lift values for each (brand, aspirational word) pair"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 189,
   "id": "b4a005bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "recorded_combo = []\n",
    "lift=[]\n",
    "ctr_brands['brand']\n",
    "\n",
    "for w1,w2 in combinations:\n",
    "    #print(w1,w2)\n",
    "    if w1 in ctr_brands_car['brand'].to_list() and w2 in asp_count_pd['aspiration'].to_list():\n",
    "        #print('here')\n",
    "        pw1 = ctr_brands_car.loc[ctr_brands_car.brand==w1]['count'].values[0]\n",
    "        pw2 = asp_count_pd.loc[asp_count_pd.aspiration==w2]['count'].values[0]\n",
    "        combo_info = combo_count.loc[combo_count.combo == (w1, w2)]['count'].values[0]\n",
    "        if pw1>0 and pw2>0:\n",
    "            recorded_combo.append((w1,w2))\n",
    "            lift.append(N*(combo_info/(pw1*pw2)))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 190,
   "id": "d0eb0b52",
   "metadata": {},
   "outputs": [],
   "source": [
    "combo_lift = pd.DataFrame({'recorded_combo':recorded_combo,'lift':lift})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 192,
   "id": "e2bfd777",
   "metadata": {},
   "outputs": [],
   "source": [
    "combo_lift.to_csv('part_e_lift.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9d6f0369",
   "metadata": {},
   "source": [
    "## Sentiment Analysis\n",
    "Recall that we performed sentiment analysis on comments. Count the most mentioned brands under comments that identified as positive sentiment."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 194,
   "id": "86c0f2d7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(619, 5)"
      ]
     },
     "execution_count": 194,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df2.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7221560e",
   "metadata": {},
   "source": [
    "we have around 619 comments that identified as postive."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 201,
   "id": "aa040314",
   "metadata": {},
   "outputs": [],
   "source": [
    "pos_brands = list(itertools.chain.from_iterable(df2.names.to_list()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 204,
   "id": "b1ab4189",
   "metadata": {},
   "outputs": [],
   "source": [
    "pos_brands_count = [x for x in pos_brands if x not in ['car','problem','sedan','seat']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 211,
   "id": "698d4513",
   "metadata": {},
   "outputs": [],
   "source": [
    "pos_brand_pd = pd.DataFrame(list(Counter(pos_brands_count).items()),columns=['brand','count']).sort_values(by='count',ascending=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "13c10715",
   "metadata": {},
   "source": [
    "which gives a similar results to brand counts, this is because many comments are surrounded around the top mentioned brands here."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 213,
   "id": "b5c57f76",
   "metadata": {},
   "outputs": [],
   "source": [
    "merged_pd = pos_brand_pd.merge(ctr_brands_car, on='brand')\n",
    "merged_pd.columns = ['brand','pos_count','total_count']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 215,
   "id": "09685c0c",
   "metadata": {},
   "outputs": [],
   "source": [
    "merged_pd['pos_pct'] = merged_pd['pos_count']/merged_pd['total_count']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 217,
   "id": "4d3b1457",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>brand</th>\n",
       "      <th>pos_count</th>\n",
       "      <th>total_count</th>\n",
       "      <th>pos_pct</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>dodge</td>\n",
       "      <td>22</td>\n",
       "      <td>72</td>\n",
       "      <td>0.305556</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>kia</td>\n",
       "      <td>40</td>\n",
       "      <td>132</td>\n",
       "      <td>0.303030</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>infiniti</td>\n",
       "      <td>3</td>\n",
       "      <td>10</td>\n",
       "      <td>0.300000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>cadillac</td>\n",
       "      <td>7</td>\n",
       "      <td>25</td>\n",
       "      <td>0.280000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>bmw</td>\n",
       "      <td>30</td>\n",
       "      <td>108</td>\n",
       "      <td>0.277778</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>mitsubishi</td>\n",
       "      <td>12</td>\n",
       "      <td>46</td>\n",
       "      <td>0.260870</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>suzuki</td>\n",
       "      <td>2</td>\n",
       "      <td>8</td>\n",
       "      <td>0.250000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>audi</td>\n",
       "      <td>10</td>\n",
       "      <td>41</td>\n",
       "      <td>0.243902</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>saturn</td>\n",
       "      <td>56</td>\n",
       "      <td>231</td>\n",
       "      <td>0.242424</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>mercury</td>\n",
       "      <td>19</td>\n",
       "      <td>81</td>\n",
       "      <td>0.234568</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>chevrolet</td>\n",
       "      <td>52</td>\n",
       "      <td>235</td>\n",
       "      <td>0.221277</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>pontiac</td>\n",
       "      <td>12</td>\n",
       "      <td>56</td>\n",
       "      <td>0.214286</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>acura</td>\n",
       "      <td>13</td>\n",
       "      <td>61</td>\n",
       "      <td>0.213115</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>buick</td>\n",
       "      <td>12</td>\n",
       "      <td>57</td>\n",
       "      <td>0.210526</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>volkswagen</td>\n",
       "      <td>20</td>\n",
       "      <td>100</td>\n",
       "      <td>0.200000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>mercedes</td>\n",
       "      <td>5</td>\n",
       "      <td>26</td>\n",
       "      <td>0.192308</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>chrysler</td>\n",
       "      <td>40</td>\n",
       "      <td>211</td>\n",
       "      <td>0.189573</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>nissan</td>\n",
       "      <td>97</td>\n",
       "      <td>514</td>\n",
       "      <td>0.188716</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>mazda</td>\n",
       "      <td>103</td>\n",
       "      <td>552</td>\n",
       "      <td>0.186594</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>toyota</td>\n",
       "      <td>167</td>\n",
       "      <td>937</td>\n",
       "      <td>0.178228</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>hyundai</td>\n",
       "      <td>98</td>\n",
       "      <td>576</td>\n",
       "      <td>0.170139</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>subaru</td>\n",
       "      <td>25</td>\n",
       "      <td>153</td>\n",
       "      <td>0.163399</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>honda</td>\n",
       "      <td>330</td>\n",
       "      <td>2061</td>\n",
       "      <td>0.160116</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ford</td>\n",
       "      <td>209</td>\n",
       "      <td>1339</td>\n",
       "      <td>0.156087</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>lincoln</td>\n",
       "      <td>7</td>\n",
       "      <td>45</td>\n",
       "      <td>0.155556</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>volvo</td>\n",
       "      <td>3</td>\n",
       "      <td>30</td>\n",
       "      <td>0.100000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         brand  pos_count  total_count   pos_pct\n",
       "12       dodge         22           72  0.305556\n",
       "9          kia         40          132  0.303030\n",
       "23    infiniti          3           10  0.300000\n",
       "20    cadillac          7           25  0.280000\n",
       "10         bmw         30          108  0.277778\n",
       "17  mitsubishi         12           46  0.260870\n",
       "25      suzuki          2            8  0.250000\n",
       "19        audi         10           41  0.243902\n",
       "6       saturn         56          231  0.242424\n",
       "14     mercury         19           81  0.234568\n",
       "7    chevrolet         52          235  0.221277\n",
       "18     pontiac         12           56  0.214286\n",
       "15       acura         13           61  0.213115\n",
       "16       buick         12           57  0.210526\n",
       "13  volkswagen         20          100  0.200000\n",
       "22    mercedes          5           26  0.192308\n",
       "8     chrysler         40          211  0.189573\n",
       "5       nissan         97          514  0.188716\n",
       "3        mazda        103          552  0.186594\n",
       "2       toyota        167          937  0.178228\n",
       "4      hyundai         98          576  0.170139\n",
       "11      subaru         25          153  0.163399\n",
       "0        honda        330         2061  0.160116\n",
       "1         ford        209         1339  0.156087\n",
       "21     lincoln          7           45  0.155556\n",
       "24       volvo          3           30  0.100000"
      ]
     },
     "execution_count": 217,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "merged_pd.sort_values(by='pos_pct',ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 218,
   "id": "b8d54c93",
   "metadata": {},
   "outputs": [],
   "source": [
    "merged_pd.to_csv('pos_comment_pct.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3d42c27b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
