{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "9ca7fe1a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#importing libraries\n",
    "import pandas as pd\n",
    "from textblob import TextBlob\n",
    "import nltk\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk import pos_tag\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.corpus import wordnet\n",
    "import collections\n",
    "from nltk.stem import WordNetLemmatizer"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "629bfbb8",
   "metadata": {},
   "source": [
    "### Loading comments and model-brands data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "7e396d9f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>page</th>\n",
       "      <th>comment_id</th>\n",
       "      <th>user_id</th>\n",
       "      <th>date</th>\n",
       "      <th>comment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>3504465</td>\n",
       "      <td>410384</td>\n",
       "      <td>April 11, 2007 6:52PM</td>\n",
       "      <td>Hi Pat:You forgot the Chrysler Sebring</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>3515400</td>\n",
       "      <td>209396</td>\n",
       "      <td>April 11, 2007 7:33PM</td>\n",
       "      <td>I'm sure some folks would appreciate having th...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>3516719</td>\n",
       "      <td>457562</td>\n",
       "      <td>April 12, 2007 6:51AM</td>\n",
       "      <td>You can try to revive this topic but without b...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>3517791</td>\n",
       "      <td>410027</td>\n",
       "      <td>April 12, 2007 8:43AM</td>\n",
       "      <td>Model vs. model is exactly what we're here for...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>3518875</td>\n",
       "      <td>411850</td>\n",
       "      <td>April 13, 2007 11:49AM</td>\n",
       "      <td>The Altima is my favorite of the bunch. It is ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   page  comment_id  user_id                    date  \\\n",
       "0     1     3504465   410384   April 11, 2007 6:52PM   \n",
       "1     1     3515400   209396   April 11, 2007 7:33PM   \n",
       "2     1     3516719   457562   April 12, 2007 6:51AM   \n",
       "3     1     3517791   410027   April 12, 2007 8:43AM   \n",
       "4     1     3518875   411850  April 13, 2007 11:49AM   \n",
       "\n",
       "                                             comment  \n",
       "0           Hi Pat:You forgot the Chrysler Sebring    \n",
       "1  I'm sure some folks would appreciate having th...  \n",
       "2  You can try to revive this topic but without b...  \n",
       "3  Model vs. model is exactly what we're here for...  \n",
       "4  The Altima is my favorite of the bunch. It is ...  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = pd.read_csv('comments_raw.csv')[:5000]\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "892f0523",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>acura</th>\n",
       "      <th>integra</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>acura</td>\n",
       "      <td>Legend</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>acura</td>\n",
       "      <td>vigor</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>acura</td>\n",
       "      <td>rlx</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>acura</td>\n",
       "      <td>ILX</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>acura</td>\n",
       "      <td>MDX</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   acura integra\n",
       "0  acura  Legend\n",
       "1  acura   vigor\n",
       "2  acura     rlx\n",
       "3  acura     ILX\n",
       "4  acura     MDX"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = pd.read_csv('models.csv')\n",
    "model.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "7ec7b838",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_dict = dict(zip(model.integra, model.acura))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "16cba6b2",
   "metadata": {},
   "source": [
    "#### Removing non-brand keys from the model-brand dictionary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "53baac1a",
   "metadata": {},
   "outputs": [],
   "source": [
    "del model_dict[\"cars\"]\n",
    "del model_dict[\"seats\"]\n",
    "del model_dict[\"problems\"]\n",
    "del model_dict[\"sedans\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f61cca2e",
   "metadata": {},
   "source": [
    "#### Replacing models with brands"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "762b7e18",
   "metadata": {},
   "outputs": [],
   "source": [
    "def replace_all(text):\n",
    "    for i, j in model_dict.items():\n",
    "        text = text.replace(i, j.lower())\n",
    "    return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "82ce45d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "data['com_replaced'] = data['comment'].apply(replace_all)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "687616dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "models_input = model.acura.unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "1d355a8d",
   "metadata": {},
   "outputs": [],
   "source": [
    "brand_list = models_input.tolist()\n",
    "brand_list.remove(\"problem\")\n",
    "brand_list.remove(\"car\")\n",
    "brand_list.remove(\"seat\")\n",
    "brand_list.remove(\"sedan\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "69baf643",
   "metadata": {},
   "outputs": [],
   "source": [
    "wl = WordNetLemmatizer()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "038e35ce",
   "metadata": {},
   "source": [
    "### Data cleaning and pre-processing"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "07520df2",
   "metadata": {},
   "source": [
    "#### Getting part-of-speech tags for comments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "4768943e",
   "metadata": {},
   "outputs": [],
   "source": [
    "pos_dict = {'J':wordnet.ADJ, 'V':wordnet.VERB, 'N':wordnet.NOUN, 'R':wordnet.ADV}\n",
    "def token_stop_pos(text):\n",
    "    tags = pos_tag(word_tokenize(text))\n",
    "    newlist = []\n",
    "    for word, tag in tags:\n",
    "        #print(word,tag)\n",
    "        if word.lower() not in set(stopwords.words('english')):\n",
    "            newlist.append(tuple([word.lower(), pos_dict.get(tag[0])]))\n",
    "    return newlist\n",
    "\n",
    "data['pos'] = data['comment'].apply(token_stop_pos)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bb10c15a",
   "metadata": {},
   "source": [
    "#### lemmatizing comments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "399bc92f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def lemmatize(pos_data):\n",
    "    lemma_rew = \" \"\n",
    "    for word, pos in pos_data:\n",
    "        #print(word,pos)\n",
    "        if not pos:\n",
    "            #print(lemma)\n",
    "            lemma = word\n",
    "            lemma_rew = lemma_rew + \" \" + lemma\n",
    "        else:\n",
    "            #print(\"else\")\n",
    "            lemma = wl.lemmatize(word, pos=pos)\n",
    "            lemma_rew = lemma_rew + \" \" + lemma\n",
    "    return lemma_rew\n",
    "\n",
    "data['Lemma'] = data['pos'].apply(lemmatize)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dab47d25",
   "metadata": {},
   "source": [
    "#### performing sentiment analysis on comments"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "24f4347b",
   "metadata": {},
   "source": [
    "This is to understand the context of the aspirational words used with reference to brands.\n",
    "TextBlob functions gives output in the form a tuple with two values:\n",
    "- Positivity (range: -1 to 1): Here, 1 and -1 represent extreme positive and negative ends respectively.\n",
    "- Subjectivity (range: 0 to 1): Here, 0 represents the statement in general context and one represents the statement in subjective context."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "7d5b2d8e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def datablob(lemma):\n",
    "    return TextBlob(lemma).sentiment\n",
    "\n",
    "data['Blob'] = data['Lemma'].apply(datablob)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5b7469f4",
   "metadata": {},
   "source": [
    "#### Defining a set of aspirational words to look out for in comments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "d15496fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "aspiration = ['Premium', 'luxury', 'lux', 'grace', 'style', 'buy', 'wishlist', 'wish', 'own', 'dream', 'expensive', \n",
    "              'class', 'swift', 'smooth', 'pricey', 'elite', 'favorite', 'brand']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e8f48d0c",
   "metadata": {},
   "source": [
    "#### Finding aspirational words from above defined list in the comments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "645c1a6f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def aspire(Lemma):\n",
    "    tokens = word_tokenize(Lemma)\n",
    "    aspire_words=[]\n",
    "    for item in tokens: \n",
    "        if item.lower() in (string.lower() for string in aspiration) and item.lower() not in (string.lower() for string in aspire_words):\n",
    "            aspire_words.append(item.lower())\n",
    "    return aspire_words\n",
    "\n",
    "data['Aspire'] = data['Lemma'].apply(aspire)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "16d8e155",
   "metadata": {},
   "source": [
    "#### Only keeping rows which detected aspirational words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "32c2c7b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = data.loc[data['Aspire'].str.len() >= 1]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9b967eee",
   "metadata": {},
   "source": [
    "#### Getting brand names from the comments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "440198e0",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-17-6d44eb055be5>:9: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df['names'] = df['pos'].apply(get_name)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>page</th>\n",
       "      <th>comment_id</th>\n",
       "      <th>user_id</th>\n",
       "      <th>date</th>\n",
       "      <th>comment</th>\n",
       "      <th>com_replaced</th>\n",
       "      <th>pos</th>\n",
       "      <th>Lemma</th>\n",
       "      <th>Blob</th>\n",
       "      <th>Aspire</th>\n",
       "      <th>names</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>3518875</td>\n",
       "      <td>411850</td>\n",
       "      <td>April 13, 2007 11:49AM</td>\n",
       "      <td>The Altima is my favorite of the bunch. It is ...</td>\n",
       "      <td>The Altima is my favorite of the bunch. It is ...</td>\n",
       "      <td>[(altima, n), (favorite, n), (bunch, n), (., N...</td>\n",
       "      <td>altima favorite bunch . amongst fast best ha...</td>\n",
       "      <td>(0.15833333333333335, 0.5805555555555557)</td>\n",
       "      <td>[favorite, expensive]</td>\n",
       "      <td>[ford, nissan, mazda, hyundai, kia]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>1</td>\n",
       "      <td>3521034</td>\n",
       "      <td>410821</td>\n",
       "      <td>April 13, 2007 12:18PM</td>\n",
       "      <td>Buick LaCrossePassat(Audi A6 in non-lux trim)V...</td>\n",
       "      <td>Buick LaCrossePassat(Audi A6 in non-lux trim)V...</td>\n",
       "      <td>[(buick, n), (lacrossepassat, n), ((, None), (...</td>\n",
       "      <td>buick lacrossepassat ( audi a6 non-lux trim ...</td>\n",
       "      <td>(-0.038888888888888896, 0.33888888888888885)</td>\n",
       "      <td>[luxury]</td>\n",
       "      <td>[buick, audi, volvo]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>1</td>\n",
       "      <td>3504466</td>\n",
       "      <td>380418</td>\n",
       "      <td>April 13, 2007 12:32PM</td>\n",
       "      <td>My daily driver is an '03 Maxima, and the '07 ...</td>\n",
       "      <td>My daily driver is an '03 Maxima, and the '07 ...</td>\n",
       "      <td>[(daily, a), (driver, n), ('03, a), (maxima, n...</td>\n",
       "      <td>daily driver '03 maximum , '07 altima feel f...</td>\n",
       "      <td>(0.1903030303030303, 0.5237878787878788)</td>\n",
       "      <td>[pricey]</td>\n",
       "      <td>[]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>1</td>\n",
       "      <td>3505565</td>\n",
       "      <td>411850</td>\n",
       "      <td>April 13, 2007 12:33PM</td>\n",
       "      <td>P.S. the CVT in the Altima has to be driven li...</td>\n",
       "      <td>P.S. the CVT in the Altima has to be driven li...</td>\n",
       "      <td>[(p.s, n), (., None), (cvt, n), (altima, n), (...</td>\n",
       "      <td>p.s . cvt altima drive like motorcycle . nee...</td>\n",
       "      <td>(0.12023809523809523, 0.4988095238095238)</td>\n",
       "      <td>[style, buy]</td>\n",
       "      <td>[]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>1</td>\n",
       "      <td>3506661</td>\n",
       "      <td>411850</td>\n",
       "      <td>April 13, 2007 12:39PM</td>\n",
       "      <td>Its interesting how that happens. There is no ...</td>\n",
       "      <td>Its interesting how that happens. There is no ...</td>\n",
       "      <td>[(interesting, a), (happens, v), (., None), (r...</td>\n",
       "      <td>interesting happen . real successor contour ...</td>\n",
       "      <td>(0.31722222222222224, 0.582962962962963)</td>\n",
       "      <td>[pricey]</td>\n",
       "      <td>[ford]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    page  comment_id  user_id                    date  \\\n",
       "4      1     3518875   411850  April 13, 2007 11:49AM   \n",
       "6      1     3521034   410821  April 13, 2007 12:18PM   \n",
       "9      1     3504466   380418  April 13, 2007 12:32PM   \n",
       "10     1     3505565   411850  April 13, 2007 12:33PM   \n",
       "11     1     3506661   411850  April 13, 2007 12:39PM   \n",
       "\n",
       "                                              comment  \\\n",
       "4   The Altima is my favorite of the bunch. It is ...   \n",
       "6   Buick LaCrossePassat(Audi A6 in non-lux trim)V...   \n",
       "9   My daily driver is an '03 Maxima, and the '07 ...   \n",
       "10  P.S. the CVT in the Altima has to be driven li...   \n",
       "11  Its interesting how that happens. There is no ...   \n",
       "\n",
       "                                         com_replaced  \\\n",
       "4   The Altima is my favorite of the bunch. It is ...   \n",
       "6   Buick LaCrossePassat(Audi A6 in non-lux trim)V...   \n",
       "9   My daily driver is an '03 Maxima, and the '07 ...   \n",
       "10  P.S. the CVT in the Altima has to be driven li...   \n",
       "11  Its interesting how that happens. There is no ...   \n",
       "\n",
       "                                                  pos  \\\n",
       "4   [(altima, n), (favorite, n), (bunch, n), (., N...   \n",
       "6   [(buick, n), (lacrossepassat, n), ((, None), (...   \n",
       "9   [(daily, a), (driver, n), ('03, a), (maxima, n...   \n",
       "10  [(p.s, n), (., None), (cvt, n), (altima, n), (...   \n",
       "11  [(interesting, a), (happens, v), (., None), (r...   \n",
       "\n",
       "                                                Lemma  \\\n",
       "4     altima favorite bunch . amongst fast best ha...   \n",
       "6     buick lacrossepassat ( audi a6 non-lux trim ...   \n",
       "9     daily driver '03 maximum , '07 altima feel f...   \n",
       "10    p.s . cvt altima drive like motorcycle . nee...   \n",
       "11    interesting happen . real successor contour ...   \n",
       "\n",
       "                                            Blob                 Aspire  \\\n",
       "4      (0.15833333333333335, 0.5805555555555557)  [favorite, expensive]   \n",
       "6   (-0.038888888888888896, 0.33888888888888885)               [luxury]   \n",
       "9       (0.1903030303030303, 0.5237878787878788)               [pricey]   \n",
       "10     (0.12023809523809523, 0.4988095238095238)           [style, buy]   \n",
       "11      (0.31722222222222224, 0.582962962962963)               [pricey]   \n",
       "\n",
       "                                  names  \n",
       "4   [ford, nissan, mazda, hyundai, kia]  \n",
       "6                  [buick, audi, volvo]  \n",
       "9                                    []  \n",
       "10                                   []  \n",
       "11                               [ford]  "
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def get_name(pos_data):\n",
    "    nouns = []\n",
    "    for word, pos in pos_data:\n",
    "        #print(word,pos)\n",
    "        if pos==\"n\" and word.lower() in (string.lower() for string in brand_list) and word.lower() not in (string.lower() for string in nouns):\n",
    "            nouns.append(word.lower())\n",
    "    return nouns\n",
    "\n",
    "df['names'] = df['pos'].apply(get_name)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e4552d8c",
   "metadata": {},
   "source": [
    "#### Dropping other columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "6ec52856",
   "metadata": {},
   "outputs": [],
   "source": [
    "df1 = df.drop(['page', 'comment_id', 'comment', 'user_id', 'date'], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "3ad796f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "#df1.to_csv('df1.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "59fe7806",
   "metadata": {},
   "source": [
    "#### Filtering data based on positivity and subjectivity\n",
    "- Positivity: Keeping data with positive values above 0 so that the brands are mentioned in positive context wrt aspirational words.\n",
    "- Subjectivity: Keeping data with subjective score>=0.5 so that we can assume its the subjective opinion of user regarding the brand which would suggest the user's preference towards the brand."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "31639da3",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\aishw\\anaconda3\\lib\\site-packages\\pandas\\core\\frame.py:4308: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  return super().drop(\n"
     ]
    }
   ],
   "source": [
    "df2 = df1.loc[(df1['Blob'].str[0] >= 0) & (df1['Blob'].str[1] >= 0.5)]\n",
    "df2.drop(['pos', 'Blob'], axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "4b3c23f6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>com_replaced</th>\n",
       "      <th>Lemma</th>\n",
       "      <th>Aspire</th>\n",
       "      <th>names</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>The Altima is my favorite of the bunch. It is ...</td>\n",
       "      <td>altima favorite bunch . amongst fast best ha...</td>\n",
       "      <td>[favorite, expensive]</td>\n",
       "      <td>[ford, nissan, mazda, hyundai, kia]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>My daily driver is an '03 Maxima, and the '07 ...</td>\n",
       "      <td>daily driver '03 maximum , '07 altima feel f...</td>\n",
       "      <td>[pricey]</td>\n",
       "      <td>[]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>Its interesting how that happens. There is no ...</td>\n",
       "      <td>interesting happen . real successor contour ...</td>\n",
       "      <td>[pricey]</td>\n",
       "      <td>[ford]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>I have been driving Accords for 16 years now. ...</td>\n",
       "      <td>drive accord 16 year . 12 year first one , 4...</td>\n",
       "      <td>[smooth, buy, brand]</td>\n",
       "      <td>[]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35</th>\n",
       "      <td>I just read in my Dec. 2006 issue of Motor Tre...</td>\n",
       "      <td>read dec. 2006 issue motor trend poor amount...</td>\n",
       "      <td>[class]</td>\n",
       "      <td>[]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                         com_replaced  \\\n",
       "4   The Altima is my favorite of the bunch. It is ...   \n",
       "9   My daily driver is an '03 Maxima, and the '07 ...   \n",
       "11  Its interesting how that happens. There is no ...   \n",
       "24  I have been driving Accords for 16 years now. ...   \n",
       "35  I just read in my Dec. 2006 issue of Motor Tre...   \n",
       "\n",
       "                                                Lemma                 Aspire  \\\n",
       "4     altima favorite bunch . amongst fast best ha...  [favorite, expensive]   \n",
       "9     daily driver '03 maximum , '07 altima feel f...               [pricey]   \n",
       "11    interesting happen . real successor contour ...               [pricey]   \n",
       "24    drive accord 16 year . 12 year first one , 4...   [smooth, buy, brand]   \n",
       "35    read dec. 2006 issue motor trend poor amount...                [class]   \n",
       "\n",
       "                                  names  \n",
       "4   [ford, nissan, mazda, hyundai, kia]  \n",
       "9                                    []  \n",
       "11                               [ford]  \n",
       "24                                   []  \n",
       "35                                   []  "
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df2.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "39c84039",
   "metadata": {},
   "outputs": [],
   "source": [
    "#df2.to_csv(\"df2.csv\", index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "88532f05",
   "metadata": {},
   "source": [
    "### Calculations and frequencies"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5c3637d5",
   "metadata": {},
   "source": [
    "#### Calculating frequency of different brands from the df2 dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "947be6ae",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4       None\n",
       "9       None\n",
       "11      None\n",
       "24      None\n",
       "35      None\n",
       "        ... \n",
       "4965    None\n",
       "4975    None\n",
       "4977    None\n",
       "4982    None\n",
       "4996    None\n",
       "Name: names, Length: 610, dtype: object"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "brands = []\n",
    "def get_freq(data):\n",
    "    for word in data:\n",
    "        brands.append(word)\n",
    "\n",
    "df2['names'].apply(get_freq)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4e96d556",
   "metadata": {},
   "source": [
    "#### Calculating frequency of different aspirational words from the df2 dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "23ee67fd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4       None\n",
       "9       None\n",
       "11      None\n",
       "24      None\n",
       "35      None\n",
       "        ... \n",
       "4965    None\n",
       "4975    None\n",
       "4977    None\n",
       "4982    None\n",
       "4996    None\n",
       "Name: Aspire, Length: 610, dtype: object"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "aspire_freq = []\n",
    "def get_freq_aspire(data):\n",
    "    for word in data:\n",
    "        aspire_freq.append(word)\n",
    "\n",
    "df2['Aspire'].apply(get_freq_aspire)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f5757ca5",
   "metadata": {},
   "source": [
    "#### Calculating frequency of combination of brands and aspirational words from the df2 dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "3cb115ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "combinations = []\n",
    "for w1 in brand_list:\n",
    "    for w2 in aspiration:\n",
    "        temp = (w1,w2)\n",
    "        combinations.append(temp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "af44aaa4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4       None\n",
       "9       None\n",
       "11      None\n",
       "24      None\n",
       "35      None\n",
       "        ... \n",
       "4965    None\n",
       "4975    None\n",
       "4977    None\n",
       "4982    None\n",
       "4996    None\n",
       "Name: com_replaced, Length: 610, dtype: object"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "combination_freq=[0]*len(combinations)\n",
    "\n",
    "def get_combo_freq(comment):\n",
    "    for w1,w2 in combinations:\n",
    "        if w1.lower() in comment.lower() and w2.lower() in comment.lower():\n",
    "            combination_freq[combinations.index((w1,w2))]+=1\n",
    "                             \n",
    "df2['com_replaced'].apply(get_combo_freq)  "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "57f395f8",
   "metadata": {},
   "source": [
    "#### Preparing data for lift calculation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1c68f327",
   "metadata": {},
   "source": [
    "#### Converting brand count to dictionary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "bfe027d4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'ford': 111, 'nissan': 29, 'mazda': 55, 'hyundai': 36, 'kia': 18, 'bmw': 23, 'buick': 6, 'cadillac': 7, 'honda': 144, 'audi': 9, 'chrysler': 22, 'dodge': 15, 'toyota': 62, 'acura': 10, 'mitsubishi': 5, 'saturn': 14, 'subaru': 12, 'lincoln': 6, 'mercury': 9, 'mercedes': 5, 'chevrolet': 3, 'infiniti': 1, 'suzuki': 2, 'volvo': 3, 'pontiac': 2, 'volkswagen': 1}\n"
     ]
    }
   ],
   "source": [
    "ctr_brands = dict(collections.Counter(brands))\n",
    "print(ctr_brands)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fb9efc70",
   "metadata": {},
   "source": [
    "#### Converting aspirational word count to dictionary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "093a09ea",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'favorite': 20, 'expensive': 32, 'pricey': 9, 'smooth': 44, 'buy': 289, 'brand': 61, 'class': 98, 'own': 108, 'style': 71, 'wish': 31, 'premium': 31, 'luxury': 10, 'dream': 9, 'lux': 1, 'grace': 1}\n"
     ]
    }
   ],
   "source": [
    "ctr_aspire = dict(collections.Counter(aspire_freq))\n",
    "print(ctr_aspire)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f3c059f9",
   "metadata": {},
   "source": [
    "#### Calculating lift values for each (brand, aspirational word) pair"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "ca167430",
   "metadata": {},
   "outputs": [],
   "source": [
    "lift=[0]*len(combinations)\n",
    "i=0\n",
    "pw1=0\n",
    "pw2=0\n",
    "for w1,w2 in combinations:\n",
    "    if w1 in ctr_brands.keys():\n",
    "        pw1 = ctr_brands[w1]\n",
    "    if w2 in ctr_aspire.keys():\n",
    "        pw2 = ctr_aspire[w2]\n",
    "    if pw1>0 and pw2>0:\n",
    "        lift[i] = combination_freq[i]/(pw1*pw2)\n",
    "    i+=1\n",
    "    pw1=0\n",
    "    pw2=0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "ccc3f161",
   "metadata": {},
   "outputs": [],
   "source": [
    "final = pd.DataFrame(list(zip(combinations, lift)), columns =['combination', 'lift'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "2b118a2a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>combination</th>\n",
       "      <th>lift</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>(acura, luxury)</td>\n",
       "      <td>0.020000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>(acura, lux)</td>\n",
       "      <td>0.200000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>(acura, style)</td>\n",
       "      <td>0.002817</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>(acura, buy)</td>\n",
       "      <td>0.001038</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>(acura, wish)</td>\n",
       "      <td>0.009677</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>491</th>\n",
       "      <td>(volvo, buy)</td>\n",
       "      <td>0.001153</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>494</th>\n",
       "      <td>(volvo, own)</td>\n",
       "      <td>0.009259</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>496</th>\n",
       "      <td>(volvo, expensive)</td>\n",
       "      <td>0.010417</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>499</th>\n",
       "      <td>(volvo, smooth)</td>\n",
       "      <td>0.007576</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>503</th>\n",
       "      <td>(volvo, brand)</td>\n",
       "      <td>0.005464</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>242 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "            combination      lift\n",
       "1       (acura, luxury)  0.020000\n",
       "2          (acura, lux)  0.200000\n",
       "4        (acura, style)  0.002817\n",
       "5          (acura, buy)  0.001038\n",
       "7         (acura, wish)  0.009677\n",
       "..                  ...       ...\n",
       "491        (volvo, buy)  0.001153\n",
       "494        (volvo, own)  0.009259\n",
       "496  (volvo, expensive)  0.010417\n",
       "499     (volvo, smooth)  0.007576\n",
       "503      (volvo, brand)  0.005464\n",
       "\n",
       "[242 rows x 2 columns]"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "final.loc[final['lift'] > 0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "43de6585",
   "metadata": {},
   "outputs": [],
   "source": [
    "final.loc[final['lift'] > 0].to_csv(\"final.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb81b644",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2c7bece7",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
